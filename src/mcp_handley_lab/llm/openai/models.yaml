models:
  gpt-5:
    # Model metadata
    description: "OpenAI's flagship model for coding, reasoning, and agentic tasks across domains"
    capabilities: "üéØ Best for: Complex coding tasks, advanced reasoning, agentic workflows"
    tags: ["latest", "general", "premium", "vision"]
    context_window: "400,000 tokens"
    output_tokens: 128000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 1.25
    output_per_1m: 10.00
    cached_input_per_1m: 0.125
    supports_caching: true

  gpt-5-mini:
    # Model metadata
    description: "Faster, more cost-efficient version of GPT-5 for well-defined tasks"
    capabilities: "‚öñÔ∏è Best for: Most coding tasks, balanced performance and cost"
    tags: ["latest", "general", "cost-effective", "vision"]
    context_window: "400,000 tokens"
    output_tokens: 128000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 0.25
    output_per_1m: 2.00
    cached_input_per_1m: 0.025
    supports_caching: true

  gpt-5-nano:
    # Model metadata
    description: "Fastest, most cost-efficient version of GPT-5 for simple tasks"
    capabilities: "‚ö° Best for: Quick tasks, high-volume processing, cost optimization"
    tags: ["latest", "general", "fast", "cost-effective", "vision"]
    context_window: "400,000 tokens"
    output_tokens: 128000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 0.05
    output_per_1m: 0.40
    cached_input_per_1m: 0.005
    supports_caching: true

  gpt-5-chat-latest:
    # Model metadata
    description: "GPT-5 model used in ChatGPT with latest optimizations"
    capabilities: "üéØ Best for: Conversational AI, chat applications, interactive tasks"
    tags: ["latest", "general", "premium", "vision", "chat"]
    context_window: "400,000 tokens"
    output_tokens: 128000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 1.25
    output_per_1m: 10.00
    cached_input_per_1m: 0.125
    supports_caching: true

  o3:
    # Model metadata
    description: "Most powerful reasoning model with leading performance on coding, math, science, and vision"
    capabilities: "üéØ Best for: Complex reasoning, advanced problem solving, scientific analysis"
    tags: ["reasoning", "latest", "premium"]
    context_window: "128,000 tokens"
    output_tokens: 100000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 2.00
    output_per_1m: 8.00

  o4-mini:
    # Model metadata
    description: "Faster, cost-efficient reasoning model delivering strong performance on math, coding and vision"
    capabilities: "‚öñÔ∏è Best for: Most reasoning tasks, cost-effective complex problems"
    tags: ["reasoning", "latest", "cost-effective"]
    context_window: "128,000 tokens"
    output_tokens: 100000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 1.00
    output_per_1m: 4.00

  o1:
    # Model metadata
    description: "Advanced reasoning model for complex problems"
    capabilities: "üìö Best for: Legacy reasoning tasks, complex analysis"
    tags: ["reasoning", "legacy"]
    context_window: "128,000 tokens"
    output_tokens: 100000
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 15.00
    output_per_1m: 60.00

  o1-preview:
    # Model metadata
    description: "Preview version of o1 reasoning model"
    capabilities: "üî¨ Best for: Testing reasoning capabilities"
    tags: ["reasoning", "preview", "legacy"]
    context_window: "128,000 tokens"
    output_tokens: 32768
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 15.00
    output_per_1m: 60.00

  o1-mini:
    # Model metadata
    description: "Smaller, faster reasoning model"
    capabilities: "‚ö° Best for: Quick reasoning tasks, cost-sensitive analysis"
    tags: ["reasoning", "cost-effective", "legacy"]
    context_window: "128,000 tokens"
    output_tokens: 65536
    param: "max_completion_tokens"
    supports_temperature: false

    # Pricing
    input_per_1m: 3.00
    output_per_1m: 12.00

  gpt-4.1:
    # Model metadata
    description: "Smartest model for complex tasks"
    capabilities: "üéØ Best for: Complex analysis, advanced reasoning, difficult problems"
    tags: ["latest", "general", "premium"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 2.00
    output_per_1m: 8.00
    cached_input_per_1m: 0.50
    supports_caching: true

  gpt-4.1-mini:
    # Model metadata
    description: "Affordable model balancing speed and intelligence"
    capabilities: "‚öñÔ∏è Best for: Most general tasks, balanced performance"
    tags: ["latest", "general", "cost-effective"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 0.40
    output_per_1m: 1.60
    cached_input_per_1m: 0.10
    supports_caching: true

  gpt-4.1-nano:
    # Model metadata
    description: "Fastest, most cost-effective model for low-latency tasks"
    capabilities: "‚ö° Best for: Quick tasks, high-volume processing, cost optimization"
    tags: ["latest", "general", "fast", "cost-effective"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 0.10
    output_per_1m: 0.40
    cached_input_per_1m: 0.025
    supports_caching: true

  gpt-4o:
    # Model metadata
    description: "Advanced multimodal model with vision and text capabilities"
    capabilities: "üéØ Best for: Image analysis, document processing, multimodal tasks"
    tags: ["multimodal", "vision", "general"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 2.50
    output_per_1m: 10.00
    cached_input_per_1m: 1.25
    supports_caching: true

  gpt-4o-mini:
    # Model metadata
    description: "Faster, cost-effective multimodal model"
    capabilities: "‚ö° Best for: Quick image analysis, everyday multimodal tasks"
    tags: ["multimodal", "vision", "cost-effective"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 0.15
    output_per_1m: 0.60
    cached_input_per_1m: 0.075
    supports_caching: true

  gpt-4o-2024-11-20:
    # Model metadata
    description: "GPT-4o snapshot from November 2024"
    capabilities: "üìö Best for: Consistent behavior, reproducible results"
    tags: ["multimodal", "vision", "snapshot"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 2.50
    output_per_1m: 10.00
    supports_caching: false

  gpt-4o-2024-08-06:
    # Model metadata
    description: "GPT-4o snapshot from August 2024"
    capabilities: "üìö Best for: Consistent behavior, reproducible results"
    tags: ["multimodal", "vision", "snapshot"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 2.50
    output_per_1m: 10.00
    supports_caching: false

  gpt-4o-mini-2024-07-18:
    # Model metadata
    description: "GPT-4o-mini snapshot from July 2024"
    capabilities: "üìö Best for: Consistent behavior, cost-effective multimodal"
    tags: ["multimodal", "vision", "snapshot", "cost-effective"]
    context_window: "128,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 0.15
    output_per_1m: 0.60
    supports_caching: false

  gpt-image-1:
    # Model metadata
    description: "Latest multimodal model for precise, high-fidelity image generation"
    capabilities: "üé® Best for: High-quality image creation, artistic generation"
    tags: ["image-generation", "latest", "multimodal"]
    context_window: "N/A (Image generation)"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Complex pricing (per modality and per image)
    text_input_per_1m: 5.00
    image_input_per_1m: 10.00
    cached_text_input_per_1m: 1.25
    cached_image_input_per_1m: 2.50
    image_output_pricing:
      low: 0.01
      medium: 0.04
      high: 0.17
    supports_caching: true
    pricing_type: "complex"

  dall-e-3:
    # Model metadata
    description: "High-quality image generation with prompt adherence"
    capabilities: "üé® Best for: Creative image generation, artistic tasks"
    tags: ["image-generation", "legacy"]
    context_window: "N/A (Image generation)"

    # Pricing
    price_per_image: 0.040
    pricing_type: "per_image"

  dall-e-2:
    # Model metadata
    description: "Previous generation image model"
    capabilities: "üé® Best for: Simple image generation, cost-effective creation"
    tags: ["image-generation", "legacy", "cost-effective"]
    context_window: "N/A (Image generation)"

    # Pricing
    price_per_image: 0.020
    pricing_type: "per_image"

  gpt-4-turbo:
    # Model metadata
    description: "Previous generation GPT-4 model"
    capabilities: "üìö Best for: Legacy applications, established workflows"
    tags: ["legacy", "general"]
    context_window: "128,000 tokens"
    output_tokens: 4096
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 10.00
    output_per_1m: 30.00
    supports_caching: false

  gpt-4:
    # Model metadata
    description: "Original GPT-4 model"
    capabilities: "üìö Best for: Established applications, proven performance"
    tags: ["legacy", "general"]
    context_window: "8,000 tokens"
    output_tokens: 8192
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 30.00
    output_per_1m: 60.00
    supports_caching: false

  gpt-3.5-turbo:
    # Model metadata
    description: "Fast, cost-effective model for simple tasks"
    capabilities: "‚ö° Best for: Simple tasks, high-volume processing, cost optimization"
    tags: ["legacy", "general", "cost-effective", "fast"]
    context_window: "16,000 tokens"
    output_tokens: 16384
    param: "max_tokens"
    supports_temperature: true

    # Pricing
    input_per_1m: 0.50
    output_per_1m: 1.50
    supports_caching: false

# Fine-tuning models
fine_tuning:
  gpt-4.1:
    input_per_1m: 3.00
    output_per_1m: 12.00
    cached_input_per_1m: 0.75
    training_per_1m: 25.00

  gpt-4.1-mini:
    input_per_1m: 0.80
    output_per_1m: 3.20
    cached_input_per_1m: 0.20
    training_per_1m: 5.00

  gpt-4.1-nano:
    input_per_1m: 0.20
    output_per_1m: 0.80
    cached_input_per_1m: 0.05
    training_per_1m: 1.50

  o4-mini:
    input_per_1m: 4.00
    output_per_1m: 16.00
    cached_input_per_1m: 1.00
    training_per_hour: 100.00

# Built-in tools pricing
tools:
  code_interpreter: 0.03  # per session
  file_search_storage: 0.10  # per GB per day
  file_search_tool_call: 2.50  # per 1k calls
  web_search_tool_call: 25.00  # per 1k calls (varies by model)

# Batch API discount
batch_discount: 0.50  # 50% off inputs and outputs

# Display categories (how to group models by tags for presentation)
display_categories:
  - name: "üß† Reasoning Models"
    tags: ["reasoning"]
    description: "Advanced models for complex problem solving and analysis"
  - name: "üí≠ Latest Language Models"
    tags: ["latest", "general"]
    exclude_tags: ["reasoning", "multimodal"]
    description: "Newest general-purpose language models"
  - name: "üëÅÔ∏è Multimodal Models"
    tags: ["multimodal", "vision"]
    exclude_tags: ["image-generation"]
    description: "Models with vision and text capabilities"
  - name: "üé® Image Generation"
    tags: ["image-generation"]
    description: "Models for creating images from text"
  - name: "üìú Legacy Models"
    tags: ["legacy"]
    exclude_tags: ["reasoning"]
    description: "Previous generation models for established workflows"

# Default model
default_model: "gpt-5"

# Usage notes
usage_notes:
  - "GPT-5 models have 400K context window and support vision (image analysis)"
  - "GPT-5 models support cached input pricing for cost optimization"
  - "Reasoning models (o1, o3, o4) don't support temperature parameter"
  - "Vision models (gpt-4o series, gpt-5 series) support image analysis"
  - "Image generation models charge per image, not per token"
  - "Use snapshots for reproducible behavior across deployments"
  - "Batch API provides 50% discount on inputs and outputs"
  - "Cached input pricing available via Responses API"
  - "Fine-tuning models have separate training costs"
  - "Built-in tools have additional per-use charges"
