interactions:
- request:
    body: '{"contents": [{"parts": [{"text": "What is configured in this YAML file?
      What is the application name?"}, {"text": "[File: tmpq2d1on6s.yaml]\n# Configuration
      file\napp:\n  name: \"Test Application\"\n  version: \"1.0.0\"\n  features:\n    -
      authentication\n    - logging\n    - metrics\ndatabase:\n  host: \"localhost\"\n  port:
      5432\n  name: \"testdb\"\n"}], "role": "user"}], "generationConfig": {"temperature":
      0.7, "maxOutputTokens": 65536}}'
    headers:
      accept:
      - '*/*'
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '445'
      content-type:
      - application/json
      host:
      - generativelanguage.googleapis.com
      user-agent:
      - google-genai-sdk/1.24.0 gl-python/3.13.3
      x-goog-api-client:
      - google-genai-sdk/1.24.0 gl-python/3.13.3
    method: POST
    uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent
  response:
    body:
      string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\":
        [\n          {\n            \"text\": \"This YAML file configures details
        for an application and its database connection.\\n\\n**What is configured
        in this YAML file?**\\n\\nThe file configures:\\n\\n1.  **Application Details
        (`app`):**\\n    *   **Name:** \\\"Test Application\\\"\\n    *   **Version:**
        \\\"1.0.0\\\"\\n    *   **Features:** A list of enabled features for the application,
        including `authentication`, `logging`, and `metrics`.\\n\\n2.  **Database
        Connection Details (`database`):**\\n    *   **Host:** \\\"localhost\\\" (indicating
        the database server is on the same machine or accessible via localhost)\\n
        \   *   **Port:** 5432 (a common default port for PostgreSQL)\\n    *   **Name:**
        \\\"testdb\\\" (the name of the database to connect to)\\n\\n**What is the
        application name?**\\n\\nThe application name configured in this YAML file
        is: **\\\"Test Application\\\"**\"\n          }\n        ],\n        \"role\":
        \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n
        \   }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 99,\n    \"candidatesTokenCount\":
        200,\n    \"totalTokenCount\": 942,\n    \"promptTokensDetails\": [\n      {\n
        \       \"modality\": \"TEXT\",\n        \"tokenCount\": 99\n      }\n    ],\n
        \   \"thoughtsTokenCount\": 643\n  },\n  \"modelVersion\": \"gemini-2.5-flash\",\n
        \ \"responseId\": \"bDFqaKO1NpmGxs0PtO3VmQI\"\n}\n"
    headers:
      Alt-Svc:
      - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
      Content-Type:
      - application/json; charset=UTF-8
      Date:
      - Sun, 06 Jul 2025 08:18:52 GMT
      Server:
      - scaffolding on HTTPServer2
      Server-Timing:
      - gfet4t7; dur=4116
      Transfer-Encoding:
      - chunked
      Vary:
      - Origin
      - X-Origin
      - Referer
      X-Content-Type-Options:
      - nosniff
      X-Frame-Options:
      - SAMEORIGIN
      X-XSS-Protection:
      - '0'
      content-length:
      - '1355'
    status:
      code: 200
      message: OK
version: 1
